#################################################################################
# Licensed to the .NET Foundation under one or more agreements.                 #
# The .NET Foundation licenses this file to you under the MIT license.          #
# See the LICENSE file in the project root for more information.                #
#################################################################################

# This job processes code coverage reports generated during test runs, merges
# them, generates code coverage reports, publishes them to the pipeline, and
# uploads them to CodeCov.

parameters:

  # True to include debug steps.
  - name: debug
    type: boolean
    default: false

  # True to upload code coverage results to CodeCov.
  - name: upload
    type: boolean

jobs:
  - job: publish_code_coverage
    displayName: Publish Code Coverage

    pool:
      name: Azure Pipelines
      vmImage: ubuntu-latest

    variables:
      # Use a temp directory that is cleaned up after each job runs.  This helps
      # avoid disk space issues on pooled agents that may run many jobs before
      # being retired.
      - name: workingDir
        value: $(Agent.TempDirectory)/coverage

    steps:

      - ${{if eq(parameters.debug, true)}}:
        - script: df -h
          displayName: '[Debug] Show Disk Usage'

        - script: env | sort
          displayName: '[Debug] List Environment Variables'

      # Install the .NET SDK.
      - template: /eng/pipelines/steps/install-dotnet.yml@self
        parameters:
          debug: ${{ parameters.debug }}

      # Install additional dotnet tools.
      #
      # We must work around a bug in the dotnet CLI that prevents tool installs
      # when multiple project/solution files are present in the working
      # directory:
      #
      # https://github.com/dotnet/sdk/issues/9623
      #
      # Our repo root (the default working directory for tasks) contains more
      # than one project file.  However, we must also obey the NuGet.config in
      # the repo root to ensure that tools are installed from the correct feeds.
      # We accomplish this by copying the NuGet.config to a temp dir and then
      # instructing the dotnet CLI tasks to run from that directory.  They will
      # still install the tools globally for subsequent tasks to use.
      #
      - script: cp "$(Build.SourcesDirectory)/NuGet.config" "$(Agent.TempDirectory)/"
        displayName: Copy NuGet.config for tool installs

      - task: DotNetCoreCLI@2
        displayName: Install dotnet-coverage tool
        inputs:
          command: custom
          custom: tool
          workingDirectory: $(Agent.TempDirectory)
          arguments: install --global dotnet-coverage --version 18.3.2

      - task: DotNetCoreCLI@2
        displayName: Install reportgenerator tool
        inputs:
          command: custom
          custom: tool
          workingDirectory: $(Agent.TempDirectory)
          arguments: install --global dotnet-reportgenerator-globaltool --version 5.5.1

      # Download all of the coverage reports from the test jobs.
      #
      # These artifacts contain the .coverage files generated during test runs,
      # along with a bunch of other files that we ignore.  We only download the
      # .coverage files.
      #
      - task: DownloadPipelineArtifact@2
        displayName: Download Coverage Reports
        inputs:
          # All of our coverage report artifact names start with 'net'.
          itemPattern: '**/net*/**/*.coverage'
          targetPath: $(workingDir)/originals

      - ${{if eq(parameters.debug, true)}}:
        - script: df -h
          displayName: '[Debug] Show Disk Usage'

        - script: ls -alFR "$(workingDir)/originals"
          displayName: '[Debug] List coverage files'

      # Merge them all into a single XML file.
      - script: >-
          dotnet-coverage merge "$(workingDir)/originals/**/*.coverage"
          --output "$(workingDir)/merge/coverage.xml"
          --output-format xml
          --log-file "$(workingDir)/merge/merge.log"
          --log-level Verbose
        displayName: Merge coverage files to XML

      - ${{if eq(parameters.debug, true)}}:
        - script: df -h
          displayName: '[Debug] Show Disk Usage'

      # Publish the intermediate XML coverage file as a pipeline artifact for
      # debugging purposes.
      - task: PublishPipelineArtifact@1
        displayName: Publish Merged Coverage XML
        inputs:
          targetPath: $(workingDir)/merge
          artifact: Code Coverage Merge Results

      # Convert the merged XML file into Cobertura reports for publishing, one
      # per package (MDS, AKV, etc).
      - script: >-
          reportgenerator
          "-reports:$(workingDir)/merge/coverage.xml"
          "-targetdir:$(workingDir)/cobertura/mds"
          -reporttypes:Cobertura
          "-assemblyfilters:+microsoft.data.sqlclient.dll"
          "-sourcedirs:$(Build.SourcesDirectory)/src/Microsoft.Data.SqlClient/src"
          "-classfilters:+Microsoft.Data.*"
        displayName: '[MDS] Convert to Cobertura format'

      - script: >-
          reportgenerator
          "-reports:$(workingDir)/merge/coverage.xml"
          "-targetdir:$(workingDir)/cobertura/akv"
          -reporttypes:Cobertura
          "-assemblyfilters:+microsoft.data.sqlclient.alwaysencrypted.azurekeyvaultprovider.dll"
          "-sourcedirs:$(Build.SourcesDirectory)/src/Microsoft.Data.SqlClient/add-ons/AzureKeyVaultProvider"
          "-classfilters:+Microsoft.Data.*"
        displayName: '[AKV] Convert to Cobertura format'

      - ${{if eq(parameters.debug, true)}}:
        - script: df -h
          displayName: '[Debug] Show Disk Usage'

      # Publish the Cobertura reports to the pipeline.
      - task: PublishCodeCoverageResults@2
        displayName: Publish code coverage results
        inputs:
          summaryFileLocation: $(workingDir)/cobertura/**/Cobertura.xml

      # Publish the Cobertura reports to CodeCov, if desired.
      - ${{if eq(parameters.upload, true)}}:
        # Download the CodeCov CLI
        - script: |
            curl -o "$(workingDir)/codecov" https://cli.codecov.io/latest/linux/codecov
            chmod +x "$(workingDir)/codecov"
          displayName: Download CodeCov CLI

        # We upload MDS and AKV reports separately so that CodeCov can show
        # them as separate entries in its UI.

        # Upload the MDS report.
        - script: >-
            $(workingDir)/codecov
            --verbose
            upload-process
            --fail-on-error
            -t $(CODECOV_TOKEN)
            --disable-search
            -f "$(workingDir)/cobertura/mds/Cobertura.xml"
            -F MDS
          displayName: '[MDS] Upload to CodeCov'

        # Upload the AKV report.
        - script: >-
            $(workingDir)/codecov
            --verbose
            upload-process
            --fail-on-error
            -t $(CODECOV_TOKEN)
            --disable-search
            -f "$(workingDir)/cobertura/akv/Cobertura.xml"
            -F AKV
          displayName: '[AKV] Upload to CodeCov'
